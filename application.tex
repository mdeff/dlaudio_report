\part{Application} \label{part:application}
% Apply the developed algorithm to a problem, MGR in our case.

\chapter{Problem} \label{chap:problem}
% Explain the problem we aim at solving: recognizing musical genre while being robust for e.g. deployement on a smartphone which may well be in a noisy environment.

The \gls{MGR} problem is the task of automatically recognizing the musical genre of an unknown audio clip given a set of labeled clips. A clip is unknown in the sense that only the raw audio is available, there is no access to any meta-data.

We think that this problem satisfies the hypothesizes we made in 

\section{Dataset}
% The curious case of the GTZAN dataset 

The system's performance is to be tested on GTZAN\footnote{Available at http://marsyasweb.appspot.com/download/data\_sets/}, the most used public dataset in \gls{MGR} \cite{sturm2014survey} which was created by Tzanetakis and Cook for their work on automatic \gls{MGR} \cite{tzanetakis2002GTZAN}. It consists of 1000 30-second audio clips (all truncated to $660000$ samples to not bias the classifier in any way) with 100 examples in each of 10 different categories: blues, classical, country, disco, hiphop, jazz, metal, pop, reggae and rock. All clips are sampled at 22050 Hz.

While the composition and integrity of the dataset has been disputed \cite{sturm2012GTZANanalysis}, it remains the most commonly used benchmark.

\section{Performance evaluation}

While the classification accuracy does not say all about \gls{MGR}, it proved useful for comparison purposes and is easy to asses.

%\section{Genres}
% How we can qualitatively distinguish genres.

% Music theory
% Explain how music is constructed.
%\section{Notes and frequencies}
%\section{Harmonics, chords and harmonies}

%In our genre recognition setting, a patch spectrogram\footnote{We will define it precisely in \chapref{model}, think of it as the spectrogram of some short time frame.} $\x \in \R^n$ is embedded in an $n$-dimensional space. Not all $n$-dimensional signals, however, are plausible spectrograms. We may think of the set of plausible spectrograms to lie on a lower $k$-dimensional manifold which is embedded in the $n$-dimensional space.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{System} \label{chap:system}
% Visual diagram: pre-processing, feature extraction, post-processing, classification, voting
% Inspyred by [ref lecun] which uses sparse auto-encoders.

The design of the genre recognition system is inspired by \cite{lecun2011PSDaudio}, which uses a layer of sparse auto-encoder to learn sparse representations of audio spectrograms targeted at \gls{MGR}. Although they call their encoder technique \gls{PSD} \cite{lecun2010PSD}, it is effectively a sparse auto-encoder \cite{bengio2009learningDeepAI}. The structured auto-encoder developed in \partref{algorithm} generalizes their loss function as an energy function and introduces a structuring term (\secref{manifold_learning}). A well-posed iterative scheme to solve the resulting non-convex optimization problem was proposed in \chapref{learning}.

The system mainly consists of three independent blocs:
\begin{enumerate}
	\item \textbf{Preprocessing}, whose goal is to transform the raw audio clips into spectrograms. Slicing the spectrograms in short time frames provides time invariance while the spectrograms bring higher-level features built on prior knowledge about audio signals, it  an hand-crafted features.
	\item \textbf{Features extraction}: spectrogram slices, which provide time invariance, are given as input vectors to the proposed structured auto-encoder who transforms them into a sparse and structured representation.
	\item \textbf{Classification}: the extracted features are used for genre classification after a post-processing step analog to feature pooling. The accuracy is assessed by a cross-validation scheme.
\end{enumerate}

{\color{red} figure}

\section{Pre-processing}
% Frames, CQT, LCN, feature / sample normalization
% A LCN may further increase the accuracy [ref LeCun].

\subsection{Frames}

\subsection{Constant-Q transform}
% Spectrogram with geometrically spaced frequencies.

\section{Feature extraction}
% Most accurate extraction with original model.
% Much faster approximations by ignoring some terms of the objective.

\section{Classification}
% Feature aggregation (feature vectors), linear SVM, majority voting (winner take all)
% Voting further gives a cheap confidence level about our choice.
% Multi-class: one-vs-one / one-vs-the-rest

\subsection{Feature aggregation}
% Analog to feature pooling.
% Goal: change of time scale.

\subsection{Support Vector Machine}
% Small introduction to SVM.

\subsection{Majority voting}

\subsection{Cross-validation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Implementation} \label{chap:implementation}

\section{Framework}
% Stack: numpy, scipy, matplotlib, scikit-learn, librosa
% Tools: IPython notebook, CDK cluster, matplotlib, h5py, librosa
% Explain why and how data is stored (layout) via HDF5.

\subsection{PyUNLocBoX}
% PyUNLocBoX: explains how it works

\section{Design}

\section{Performance} \label{sec:performance}

\subsection{Algorithm}
% FISTA vs PD implementation

\subsection{Approximate KNN search}
% How FLANN works, what are the alternatives.
% Techniques: KDtree, ball, local hashes (LHS)
% cosine to euclidean

\subsection{Optimization for space}
% Optimization for space: avoid copy, modify in place, float32, store Z as scipy.sparse

\subsection{Optimization for speed}
% Optimization for speed: ATLAS/OpenBLAS, float32 (memory bandwidth), projection in the ball (not on the sphere)
% ATLAS mono-threaded (at least on Ubuntu), OpenBLAS multi-threaded.
% Linear algebra: optimized version of BLAS: ATLAS and OpenBLAS. (LINPACK)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Results} \label{chap:results}
% Results and comparisons
% Include discussion in results ?

% All the simulations on a reduced dataset because of computation time.
% Only one simulation on the full set for comparison with others. So without noise, with graph.
The iterative optimization scheme presented in \chapref{learning} is, by definition, rather computationally heavy. Despite having been sped up by an order of magnitude already (see \secref{performance}), it is still quite sub-optimal from a computational point-of-view. As the algorithm itself is still a prototype, we did not want to invest too much time to further optimize its implementation. For this reason, the following experiments where all conducted on a subset of the dataset.

Furthermore, the classification accuracy was measured on individual frames, i.e. before majority voting, rather than on whole clip. The rational is to capture the confidence about the class of a clip. Another positive impact is the reduction of the variance caused by the increased number of samples.

The first presented result shows that the sparse and structured representation extracted from the spectrograms by the structured auto-encoder defined in \partref{algorithm} is indeed more discriminative than the spectrograms in a classification task.

The second experiment shows that structured representations are robust to noise.

\section{Spectrograms}
% Show example spectrograms of jazz / blues. Show how they are different (music theory) and can such be distinguished.

\section{Learned features}
% Show some atoms: harmonics, chords, harmonies, drums.
% Probably not on full CQT, should be on octaves.
%Via music theory, we know that music is constructed via some building blocks, e.g.

Although we have not observed meaningful atoms (yet), \cite{lecun2010PSD} showed that when dictionaries where trained on individual octaves, they discovered harmonics, chords and harmonies without any prior about music theory.

\section{Convergence analysis}

The encoder fidelity sub-objective is 2 orders of magnitude lower than the other sub-objectives, which suggests that the addition of the encoder does not alter the features extracted via the complete scheme defined by \eqnref{pr_encoder}.

\section{Descriptive feature vectors}
% Show aggregated feature vectors for some genres.
% How is it qualitatively more discriminative than the spectrogram ?

\section{Hyper-parameters tuning}
% Test matrix for hyper-parameters on smaller problem (i.e. less frames).
% For ld, le, lg, m
% Numerical parameters: Nouter (enough when no more inner), rtol
% Graph parameters: K, Csigma, kernel?, metric
% Classification: C, Nvectors
% Pre-processing: na=1024, ns=96

Overcompleteness, defined by the hyper-parameter $m$, must be evaluated by considering the number of code units and the effective dimensionality of the input as given by \gls{PCA}.

\section{Classification accuracy}
% On the whole dataset, not very good in comparison with others.
% Measured via 10-fold cross-validation
% How classification is improved by feature learning, introducing the encoder / graph.
% Comparison with other techniques.


\section{Scarce training set}
% Il faut juste garder à l'esprit que le graphe (et le dictionnaire) est appris sur le dataset complet. Ça peut cependant être utile si on a beaucoup de données à disposition mais que les labels coûtent chers.

\section{Robustness to noisy data}
% Final experiement: baseline, graph-less, graph vs noise level

\section{Discussion}
% Is the model appropriate for the problem ?

\begin{table}
	\begin{center}
		\begin{tabular}{|l|l|l|}
			\hline
			Classifier & Features & Acc. (\%) \\
			\hline
			linear SVM & raw audio & 0 \\
			linear SVM & CQT spectrogram & 0 \\
			linear SVM & normalized CQT spectrogram & 0 \\
			linear SVM & features from \eqnref{basispursuit} & 0 \\
			linear SVM & features from \eqnref{minz} & 0 \\
			linear SVM & features from \eqnref{extraction} & 0 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Genre recognition accuracy of various algorithms on GTZAN.}
	\label{tab:accuracy_comparison}
\end{table}

While our results did not attain the state-of-the-art (yet) in \gls{MGR} on GTZAN, depicted in \tabref{accuracy_comparison};
we demonstrated the usefulness of an important property of the proposed model: the conservation of the structure in the data, which allows the system to be robust to noisy data as well as being able to generalize with a very scarce training set.
%we made the point that our model is useful and that we shall continue to research on it.
Higher classification accuracies are probably achievable by fine-tuning the hyper-parameters and introducing further tricks: e.g. by applying a \gls{LCN} to the \gls{CQT} spectrograms or working on individual octaves, two techniques used by \cite{lecun2011PSDaudio}. We may even further improve the performance of our model by creating a better graph, i.e. a graph more adapted to the problem at hand, by fine-tuning the hyper-parameters.